# proj115-auto-complete-for-testscript
基于Transformer实现测试脚本代码自动补全

## 项目描述

较之工程代码，测试代码更加具备规律性，同测试框架下具有高度结构重复性，并且编写逻辑并不复杂。此外对于不同用例而言，业务上存在着相同AW、函数调用的可能，但对于社区而言，此可复用性没有得到合理的管理和使用。因此利用人工智能技术根据描述的语义直接生成特定框架下的下文测试代码将会大幅提高社区测试脚本编写效率。
此前OpenAI基于Google的Transformer论文开发了GPT模型架构，并基于GPT-3实现了CodeX这个通用代码生成预测模型。此项目希望基于相同的或者改进的Tranformer模型，利用海量测试脚本代码训练通用模型，再通过特定框架的标注数据进行Fine-Tune获得对应框架的预测生成模型，并通过API集成相应上层工具中。
在保障准确率的前提下，实现提高测试脚本编写效率提高60%的目标。

## 所属赛道

2022全国大学生操作系统比赛的“OS功能设计”赛道

## 参赛要求

- 以小组为单位参赛，最多三人一个小组，且小组成员是来自同一所高校的本科生（2022年春季学期或之后本科毕业的大一~大四的学生）
- 如学生参加了多个项目，参赛学生选择一个自己参加的项目参与评奖
- 请遵循“2022全国大学生操作系统比赛”的章程和技术方案要求

## 难度

高

## 特征

- 利用工具爬取海量测试脚本代码数据，并完成所需数据处理
- 通过现有前沿Transformer的调研、实验，选取构建最适用于测试脚本代码的Transformer模型架构（如GPT-2、BERT等）
- 构建具备预训练、Fine-Tune、调用既有模型API的端到端项目

## 进阶特性

- 实现模型改进，基于前沿Transformer调优文献，针对性改进所用Transformer模型，优化最终准确率

## License

任意开源license都可

## 预期目标

特征中的要求为必备能力，进阶特性为建议内容，不要求一定完成。选择本项目的同学也可提出自己的新想法，得到导师任何支持后亦可加入预期目标或进阶特性。
